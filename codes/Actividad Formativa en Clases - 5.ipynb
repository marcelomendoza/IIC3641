{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49178600",
   "metadata": {},
   "source": [
    "# IIC-3641 GML UC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2945a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Actividad en clase\n",
    "\n",
    "Vamos a usar GCN para trabajar con el dataset CORA:\n",
    "\n",
    "- Modifique la arquitectura de la clase Net hasta lograr que el accuracy sea mejor que el que mostré en clases.\n",
    "- Defina una función de early stopping que guarde los modelos cuando se obtengan mejoras en la función de pérdida. Puede detener el entrenamiento con un parámetro patience que hace un break si no se obtienen mejoras despues de una cantidad determinada de epochs.\n",
    "- Grafique las funciones de pérdida y de accuracy.\n",
    "- Cuanto termine, me avisa para entregarle una **L (logrado)**.\n",
    "- Recuerde que las L otorgan un bono en la nota final de la asignatura.\n",
    "\n",
    "***Tiene hasta el final de la clase.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e0e96e-294c-4bb9-8a4a-94f629c4ebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ebe864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "gcn_msg = fn.copy_u(u=\"h\", out=\"m\")\n",
    "gcn_reduce = fn.sum(msg=\"m\", out=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29224508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import CoraGraphDataset\n",
    "\n",
    "\n",
    "def load_cora_data():\n",
    "    dataset = CoraGraphDataset()\n",
    "    g = dataset[0]\n",
    "    features = g.ndata[\"feat\"]\n",
    "    labels = g.ndata[\"label\"]\n",
    "    train_mask = g.ndata[\"train_mask\"]\n",
    "    test_mask = g.ndata[\"test_mask\"]\n",
    "    return g, features, labels, train_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4775cb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "g, features, labels, train_mask, test_mask = load_cora_data()\n",
    "g.add_edges(g.nodes(), g.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f3e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        with g.local_scope():\n",
    "            g.ndata[\"h\"] = feature\n",
    "            g.update_all(gcn_msg, gcn_reduce)\n",
    "            h = g.ndata[\"h\"]\n",
    "            return self.linear(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75659447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): GCNLayer(\n",
      "    (linear): Linear(in_features=1433, out_features=64, bias=True)\n",
      "  )\n",
      "  (layer2): GCNLayer(\n",
      "    (linear): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = GCNLayer(1433, 64)\n",
    "        self.layer2 = GCNLayer(64, 7)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = F.relu(self.layer1(g, features))\n",
    "        x = self.layer2(g, x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17bdf514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        logits = model(g, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = th.max(logits, dim=1)\n",
    "        correct = th.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60918a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, path='best_model.pth'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Número de épocas que esperará sin mejora antes de detener el entrenamiento.\n",
    "            delta (float): Mínima mejora requerida para ser considerada una mejora.\n",
    "            path (str): Ruta para guardar el mejor modelo.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Guarda el mejor modelo cuando ocurre una mejora en la pérdida de validación.'''\n",
    "        print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "# Uso en el ciclo de entrenamiento:\n",
    "early_stopping = EarlyStopping(patience=3, delta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc3de577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 1.9538 | Test Acc 0.2270 | Time(s) 0.0183\n",
      "Validation loss decreased (inf --> 1.953823). Saving model...\n",
      "Epoch 00001 | Loss 1.6977 | Test Acc 0.5530 | Time(s) 0.0123\n",
      "Validation loss decreased (1.953823 --> 1.697688). Saving model...\n",
      "Epoch 00002 | Loss 1.4845 | Test Acc 0.7360 | Time(s) 0.0100\n",
      "Validation loss decreased (1.697688 --> 1.484530). Saving model...\n",
      "Epoch 00003 | Loss 1.2885 | Test Acc 0.7730 | Time(s) 0.0089\n",
      "Validation loss decreased (1.484530 --> 1.288514). Saving model...\n",
      "Epoch 00004 | Loss 1.0977 | Test Acc 0.7670 | Time(s) 0.0082\n",
      "Validation loss decreased (1.288514 --> 1.097701). Saving model...\n",
      "Epoch 00005 | Loss 0.9308 | Test Acc 0.7620 | Time(s) 0.0077\n",
      "Validation loss decreased (1.097701 --> 0.930785). Saving model...\n",
      "Epoch 00006 | Loss 0.7941 | Test Acc 0.7580 | Time(s) 0.0074\n",
      "Validation loss decreased (0.930785 --> 0.794141). Saving model...\n",
      "Epoch 00007 | Loss 0.6744 | Test Acc 0.7610 | Time(s) 0.0072\n",
      "Validation loss decreased (0.794141 --> 0.674374). Saving model...\n",
      "Epoch 00008 | Loss 0.5707 | Test Acc 0.7510 | Time(s) 0.0071\n",
      "Validation loss decreased (0.674374 --> 0.570706). Saving model...\n",
      "Epoch 00009 | Loss 0.4834 | Test Acc 0.7580 | Time(s) 0.0069\n",
      "Validation loss decreased (0.570706 --> 0.483398). Saving model...\n",
      "Epoch 00010 | Loss 0.4098 | Test Acc 0.7610 | Time(s) 0.0068\n",
      "Validation loss decreased (0.483398 --> 0.409754). Saving model...\n",
      "Epoch 00011 | Loss 0.3434 | Test Acc 0.7610 | Time(s) 0.0067\n",
      "Validation loss decreased (0.409754 --> 0.343352). Saving model...\n",
      "Epoch 00012 | Loss 0.2875 | Test Acc 0.7560 | Time(s) 0.0066\n",
      "Validation loss decreased (0.343352 --> 0.287522). Saving model...\n",
      "Epoch 00013 | Loss 0.2424 | Test Acc 0.7580 | Time(s) 0.0065\n",
      "Validation loss decreased (0.287522 --> 0.242354). Saving model...\n",
      "Epoch 00014 | Loss 0.2043 | Test Acc 0.7660 | Time(s) 0.0064\n",
      "Validation loss decreased (0.242354 --> 0.204286). Saving model...\n",
      "Epoch 00015 | Loss 0.1721 | Test Acc 0.7700 | Time(s) 0.0064\n",
      "Validation loss decreased (0.204286 --> 0.172077). Saving model...\n",
      "Epoch 00016 | Loss 0.1450 | Test Acc 0.7690 | Time(s) 0.0063\n",
      "Validation loss decreased (0.172077 --> 0.144960). Saving model...\n",
      "Epoch 00017 | Loss 0.1219 | Test Acc 0.7700 | Time(s) 0.0063\n",
      "Validation loss decreased (0.144960 --> 0.121899). Saving model...\n",
      "Epoch 00018 | Loss 0.1021 | Test Acc 0.7690 | Time(s) 0.0063\n",
      "Validation loss decreased (0.121899 --> 0.102131). Saving model...\n",
      "Epoch 00019 | Loss 0.0853 | Test Acc 0.7640 | Time(s) 0.0063\n",
      "Validation loss decreased (0.102131 --> 0.085270). Saving model...\n",
      "Epoch 00020 | Loss 0.0710 | Test Acc 0.7630 | Time(s) 0.0063\n",
      "Validation loss decreased (0.085270 --> 0.071003). Saving model...\n",
      "Epoch 00021 | Loss 0.0590 | Test Acc 0.7610 | Time(s) 0.0063\n",
      "Validation loss decreased (0.071003 --> 0.059034). Saving model...\n",
      "Epoch 00022 | Loss 0.0490 | Test Acc 0.7620 | Time(s) 0.0063\n",
      "Validation loss decreased (0.059034 --> 0.049039). Saving model...\n",
      "Epoch 00023 | Loss 0.0407 | Test Acc 0.7600 | Time(s) 0.0062\n",
      "Validation loss decreased (0.049039 --> 0.040736). Saving model...\n",
      "Epoch 00024 | Loss 0.0339 | Test Acc 0.7560 | Time(s) 0.0062\n",
      "Validation loss decreased (0.040736 --> 0.033878). Saving model...\n",
      "Epoch 00025 | Loss 0.0282 | Test Acc 0.7550 | Time(s) 0.0062\n",
      "Validation loss decreased (0.033878 --> 0.028222). Saving model...\n",
      "Epoch 00026 | Loss 0.0236 | Test Acc 0.7540 | Time(s) 0.0062\n",
      "Validation loss decreased (0.028222 --> 0.023552). Saving model...\n",
      "Epoch 00027 | Loss 0.0197 | Test Acc 0.7530 | Time(s) 0.0062\n",
      "Validation loss decreased (0.023552 --> 0.019708). Saving model...\n",
      "Epoch 00028 | Loss 0.0165 | Test Acc 0.7560 | Time(s) 0.0062\n",
      "Validation loss decreased (0.019708 --> 0.016545). Saving model...\n",
      "Epoch 00029 | Loss 0.0140 | Test Acc 0.7580 | Time(s) 0.0062\n",
      "Validation loss decreased (0.016545 --> 0.013956). Saving model...\n",
      "Epoch 00030 | Loss 0.0118 | Test Acc 0.7580 | Time(s) 0.0063\n",
      "Validation loss decreased (0.013956 --> 0.011837). Saving model...\n",
      "Epoch 00031 | Loss 0.0101 | Test Acc 0.7580 | Time(s) 0.0063\n",
      "Validation loss decreased (0.011837 --> 0.010107). Saving model...\n",
      "Epoch 00032 | Loss 0.0087 | Test Acc 0.7580 | Time(s) 0.0063\n",
      "Validation loss decreased (0.010107 --> 0.008692). Saving model...\n",
      "Epoch 00033 | Loss 0.0075 | Test Acc 0.7570 | Time(s) 0.0064\n",
      "Validation loss decreased (0.008692 --> 0.007528). Saving model...\n",
      "Epoch 00034 | Loss 0.0066 | Test Acc 0.7550 | Time(s) 0.0064\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch 00035 | Loss 0.0058 | Test Acc 0.7540 | Time(s) 0.0064\n",
      "Validation loss decreased (0.007528 --> 0.005767). Saving model...\n",
      "Epoch 00036 | Loss 0.0051 | Test Acc 0.7520 | Time(s) 0.0064\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch 00037 | Loss 0.0045 | Test Acc 0.7510 | Time(s) 0.0064\n",
      "Validation loss decreased (0.005767 --> 0.004514). Saving model...\n",
      "Epoch 00038 | Loss 0.0040 | Test Acc 0.7500 | Time(s) 0.0065\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch 00039 | Loss 0.0036 | Test Acc 0.7490 | Time(s) 0.0065\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch 00040 | Loss 0.0032 | Test Acc 0.7490 | Time(s) 0.0065\n",
      "Validation loss decreased (0.004514 --> 0.003234). Saving model...\n",
      "Epoch 00041 | Loss 0.0029 | Test Acc 0.7480 | Time(s) 0.0065\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch 00042 | Loss 0.0027 | Test Acc 0.7460 | Time(s) 0.0065\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch 00043 | Loss 0.0024 | Test Acc 0.7460 | Time(s) 0.0065\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "optimizer = th.optim.Adam(net.parameters(), lr=1e-2)\n",
    "dur = []\n",
    "\n",
    "train_losses = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    if epoch >= 0:\n",
    "        t0 = time.time()\n",
    "    net.train()\n",
    "    logits = net(g, features)\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch >= 0:\n",
    "        dur.append(time.time() - t0)\n",
    "    acc = evaluate(net, g, features, labels, test_mask)\n",
    "    print(\n",
    "        \"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
    "            epoch, loss.item(), acc, np.mean(dur)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    test_acc.append(acc)\n",
    "    \n",
    "    early_stopping(loss, net)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88b50a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1427610/2640716579.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a1f30c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='loss')\n",
    "plt.plot(test_acc, label='accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3869c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
