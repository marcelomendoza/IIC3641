{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6c4cc3",
   "metadata": {},
   "source": [
    "# IIC-3641 GML UC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c409ab",
   "metadata": {},
   "source": [
    "- Versiones de librerías, python 3.10.2\n",
    "- DGL: https://www.dgl.ai/pages/start.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "976c1a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f683396",
   "metadata": {},
   "source": [
    "## DGL requiere de un framework de backend. Aquí va con torch sobre cuda (GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5284e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "gcn_msg = fn.copy_u(u=\"h\", out=\"m\")\n",
    "gcn_reduce = fn.sum(msg=\"m\", out=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879cd5bf",
   "metadata": {},
   "source": [
    "## Leemos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6296406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import CoraGraphDataset\n",
    "\n",
    "\n",
    "def load_cora_data():\n",
    "    dataset = CoraGraphDataset()\n",
    "    g = dataset[0]\n",
    "    features = g.ndata[\"feat\"]\n",
    "    labels = g.ndata[\"label\"]\n",
    "    train_mask = g.ndata[\"train_mask\"]\n",
    "    test_mask = g.ndata[\"test_mask\"]\n",
    "    return g, features, labels, train_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549d7369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "g, features, labels, train_mask, test_mask = load_cora_data()\n",
    "# Add edges between each node and itself to preserve old node representations\n",
    "g.add_edges(g.nodes(), g.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdc3203",
   "metadata": {},
   "source": [
    "## Definimos una capa GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9964ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        with g.local_scope():\n",
    "            g.ndata[\"h\"] = feature\n",
    "            g.update_all(gcn_msg, gcn_reduce)\n",
    "            h = g.ndata[\"h\"]\n",
    "            return self.linear(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28aaba2",
   "metadata": {},
   "source": [
    "## Y definimos la red, en este caso de dos capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ed0b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): GCNLayer(\n",
      "    (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
      "  )\n",
      "  (layer2): GCNLayer(\n",
      "    (linear): Linear(in_features=16, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = GCNLayer(1433, 16)\n",
    "        self.layer2 = GCNLayer(16, 7)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = F.relu(self.layer1(g, features))\n",
    "        x = self.layer2(g, x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e38fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        logits = model(g, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = th.max(logits, dim=1)\n",
    "        correct = th.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393b373",
   "metadata": {},
   "source": [
    "## Y entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14973b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 1.9656 | Test Acc 0.1850 | Time(s) 0.0789\n",
      "Epoch 00001 | Loss 1.8715 | Test Acc 0.3080 | Time(s) 0.0425\n",
      "Epoch 00002 | Loss 1.7669 | Test Acc 0.4560 | Time(s) 0.0300\n",
      "Epoch 00003 | Loss 1.6615 | Test Acc 0.4910 | Time(s) 0.0237\n",
      "Epoch 00004 | Loss 1.5703 | Test Acc 0.5120 | Time(s) 0.0200\n",
      "Epoch 00005 | Loss 1.4890 | Test Acc 0.5340 | Time(s) 0.0174\n",
      "Epoch 00006 | Loss 1.4146 | Test Acc 0.5500 | Time(s) 0.0157\n",
      "Epoch 00007 | Loss 1.3460 | Test Acc 0.5760 | Time(s) 0.0144\n",
      "Epoch 00008 | Loss 1.2788 | Test Acc 0.6230 | Time(s) 0.0133\n",
      "Epoch 00009 | Loss 1.2093 | Test Acc 0.6620 | Time(s) 0.0124\n",
      "Epoch 00010 | Loss 1.1367 | Test Acc 0.6920 | Time(s) 0.0117\n",
      "Epoch 00011 | Loss 1.0630 | Test Acc 0.7060 | Time(s) 0.0112\n",
      "Epoch 00012 | Loss 0.9904 | Test Acc 0.6980 | Time(s) 0.0107\n",
      "Epoch 00013 | Loss 0.9211 | Test Acc 0.6850 | Time(s) 0.0103\n",
      "Epoch 00014 | Loss 0.8572 | Test Acc 0.6750 | Time(s) 0.0101\n",
      "Epoch 00015 | Loss 0.7989 | Test Acc 0.6740 | Time(s) 0.0098\n",
      "Epoch 00016 | Loss 0.7449 | Test Acc 0.6740 | Time(s) 0.0095\n",
      "Epoch 00017 | Loss 0.6938 | Test Acc 0.6750 | Time(s) 0.0092\n",
      "Epoch 00018 | Loss 0.6439 | Test Acc 0.6850 | Time(s) 0.0090\n",
      "Epoch 00019 | Loss 0.5953 | Test Acc 0.6900 | Time(s) 0.0088\n",
      "Epoch 00020 | Loss 0.5492 | Test Acc 0.7050 | Time(s) 0.0086\n",
      "Epoch 00021 | Loss 0.5066 | Test Acc 0.7160 | Time(s) 0.0084\n",
      "Epoch 00022 | Loss 0.4679 | Test Acc 0.7190 | Time(s) 0.0083\n",
      "Epoch 00023 | Loss 0.4327 | Test Acc 0.7210 | Time(s) 0.0081\n",
      "Epoch 00024 | Loss 0.4005 | Test Acc 0.7280 | Time(s) 0.0080\n",
      "Epoch 00025 | Loss 0.3705 | Test Acc 0.7320 | Time(s) 0.0079\n",
      "Epoch 00026 | Loss 0.3423 | Test Acc 0.7340 | Time(s) 0.0078\n",
      "Epoch 00027 | Loss 0.3161 | Test Acc 0.7360 | Time(s) 0.0077\n",
      "Epoch 00028 | Loss 0.2920 | Test Acc 0.7350 | Time(s) 0.0076\n",
      "Epoch 00029 | Loss 0.2696 | Test Acc 0.7400 | Time(s) 0.0075\n",
      "Epoch 00030 | Loss 0.2489 | Test Acc 0.7400 | Time(s) 0.0074\n",
      "Epoch 00031 | Loss 0.2297 | Test Acc 0.7410 | Time(s) 0.0073\n",
      "Epoch 00032 | Loss 0.2118 | Test Acc 0.7420 | Time(s) 0.0073\n",
      "Epoch 00033 | Loss 0.1953 | Test Acc 0.7460 | Time(s) 0.0072\n",
      "Epoch 00034 | Loss 0.1801 | Test Acc 0.7430 | Time(s) 0.0071\n",
      "Epoch 00035 | Loss 0.1661 | Test Acc 0.7430 | Time(s) 0.0070\n",
      "Epoch 00036 | Loss 0.1533 | Test Acc 0.7440 | Time(s) 0.0070\n",
      "Epoch 00037 | Loss 0.1415 | Test Acc 0.7470 | Time(s) 0.0069\n",
      "Epoch 00038 | Loss 0.1305 | Test Acc 0.7480 | Time(s) 0.0069\n",
      "Epoch 00039 | Loss 0.1205 | Test Acc 0.7490 | Time(s) 0.0068\n",
      "Epoch 00040 | Loss 0.1112 | Test Acc 0.7510 | Time(s) 0.0068\n",
      "Epoch 00041 | Loss 0.1027 | Test Acc 0.7520 | Time(s) 0.0067\n",
      "Epoch 00042 | Loss 0.0948 | Test Acc 0.7540 | Time(s) 0.0067\n",
      "Epoch 00043 | Loss 0.0876 | Test Acc 0.7530 | Time(s) 0.0066\n",
      "Epoch 00044 | Loss 0.0810 | Test Acc 0.7530 | Time(s) 0.0066\n",
      "Epoch 00045 | Loss 0.0749 | Test Acc 0.7520 | Time(s) 0.0066\n",
      "Epoch 00046 | Loss 0.0693 | Test Acc 0.7530 | Time(s) 0.0065\n",
      "Epoch 00047 | Loss 0.0642 | Test Acc 0.7520 | Time(s) 0.0065\n",
      "Epoch 00048 | Loss 0.0595 | Test Acc 0.7520 | Time(s) 0.0065\n",
      "Epoch 00049 | Loss 0.0552 | Test Acc 0.7490 | Time(s) 0.0064\n",
      "Epoch 00050 | Loss 0.0513 | Test Acc 0.7480 | Time(s) 0.0064\n",
      "Epoch 00051 | Loss 0.0477 | Test Acc 0.7470 | Time(s) 0.0064\n",
      "Epoch 00052 | Loss 0.0444 | Test Acc 0.7460 | Time(s) 0.0064\n",
      "Epoch 00053 | Loss 0.0414 | Test Acc 0.7460 | Time(s) 0.0063\n",
      "Epoch 00054 | Loss 0.0386 | Test Acc 0.7450 | Time(s) 0.0063\n",
      "Epoch 00055 | Loss 0.0361 | Test Acc 0.7450 | Time(s) 0.0063\n",
      "Epoch 00056 | Loss 0.0337 | Test Acc 0.7450 | Time(s) 0.0063\n",
      "Epoch 00057 | Loss 0.0316 | Test Acc 0.7440 | Time(s) 0.0062\n",
      "Epoch 00058 | Loss 0.0296 | Test Acc 0.7440 | Time(s) 0.0062\n",
      "Epoch 00059 | Loss 0.0278 | Test Acc 0.7440 | Time(s) 0.0062\n",
      "Epoch 00060 | Loss 0.0262 | Test Acc 0.7430 | Time(s) 0.0062\n",
      "Epoch 00061 | Loss 0.0247 | Test Acc 0.7410 | Time(s) 0.0062\n",
      "Epoch 00062 | Loss 0.0233 | Test Acc 0.7400 | Time(s) 0.0061\n",
      "Epoch 00063 | Loss 0.0220 | Test Acc 0.7400 | Time(s) 0.0061\n",
      "Epoch 00064 | Loss 0.0208 | Test Acc 0.7400 | Time(s) 0.0061\n",
      "Epoch 00065 | Loss 0.0197 | Test Acc 0.7390 | Time(s) 0.0061\n",
      "Epoch 00066 | Loss 0.0187 | Test Acc 0.7380 | Time(s) 0.0061\n",
      "Epoch 00067 | Loss 0.0177 | Test Acc 0.7380 | Time(s) 0.0060\n",
      "Epoch 00068 | Loss 0.0169 | Test Acc 0.7380 | Time(s) 0.0060\n",
      "Epoch 00069 | Loss 0.0161 | Test Acc 0.7380 | Time(s) 0.0060\n",
      "Epoch 00070 | Loss 0.0153 | Test Acc 0.7380 | Time(s) 0.0060\n",
      "Epoch 00071 | Loss 0.0147 | Test Acc 0.7390 | Time(s) 0.0060\n",
      "Epoch 00072 | Loss 0.0140 | Test Acc 0.7380 | Time(s) 0.0060\n",
      "Epoch 00073 | Loss 0.0134 | Test Acc 0.7360 | Time(s) 0.0059\n",
      "Epoch 00074 | Loss 0.0129 | Test Acc 0.7370 | Time(s) 0.0059\n",
      "Epoch 00075 | Loss 0.0124 | Test Acc 0.7380 | Time(s) 0.0059\n",
      "Epoch 00076 | Loss 0.0119 | Test Acc 0.7390 | Time(s) 0.0059\n",
      "Epoch 00077 | Loss 0.0114 | Test Acc 0.7390 | Time(s) 0.0059\n",
      "Epoch 00078 | Loss 0.0110 | Test Acc 0.7390 | Time(s) 0.0059\n",
      "Epoch 00079 | Loss 0.0106 | Test Acc 0.7390 | Time(s) 0.0059\n",
      "Epoch 00080 | Loss 0.0103 | Test Acc 0.7400 | Time(s) 0.0059\n",
      "Epoch 00081 | Loss 0.0099 | Test Acc 0.7400 | Time(s) 0.0059\n",
      "Epoch 00082 | Loss 0.0096 | Test Acc 0.7410 | Time(s) 0.0059\n",
      "Epoch 00083 | Loss 0.0093 | Test Acc 0.7400 | Time(s) 0.0058\n",
      "Epoch 00084 | Loss 0.0090 | Test Acc 0.7400 | Time(s) 0.0058\n",
      "Epoch 00085 | Loss 0.0087 | Test Acc 0.7390 | Time(s) 0.0058\n",
      "Epoch 00086 | Loss 0.0085 | Test Acc 0.7400 | Time(s) 0.0058\n",
      "Epoch 00087 | Loss 0.0082 | Test Acc 0.7390 | Time(s) 0.0058\n",
      "Epoch 00088 | Loss 0.0080 | Test Acc 0.7380 | Time(s) 0.0058\n",
      "Epoch 00089 | Loss 0.0078 | Test Acc 0.7380 | Time(s) 0.0058\n",
      "Epoch 00090 | Loss 0.0076 | Test Acc 0.7380 | Time(s) 0.0058\n",
      "Epoch 00091 | Loss 0.0074 | Test Acc 0.7380 | Time(s) 0.0058\n",
      "Epoch 00092 | Loss 0.0072 | Test Acc 0.7380 | Time(s) 0.0057\n",
      "Epoch 00093 | Loss 0.0070 | Test Acc 0.7380 | Time(s) 0.0057\n",
      "Epoch 00094 | Loss 0.0068 | Test Acc 0.7380 | Time(s) 0.0057\n",
      "Epoch 00095 | Loss 0.0067 | Test Acc 0.7390 | Time(s) 0.0057\n",
      "Epoch 00096 | Loss 0.0065 | Test Acc 0.7390 | Time(s) 0.0057\n",
      "Epoch 00097 | Loss 0.0064 | Test Acc 0.7390 | Time(s) 0.0057\n",
      "Epoch 00098 | Loss 0.0062 | Test Acc 0.7390 | Time(s) 0.0057\n",
      "Epoch 00099 | Loss 0.0061 | Test Acc 0.7390 | Time(s) 0.0057\n"
     ]
    }
   ],
   "source": [
    "optimizer = th.optim.Adam(net.parameters(), lr=1e-2)\n",
    "dur = []\n",
    "for epoch in range(100):\n",
    "    if epoch >= 0:\n",
    "        t0 = time.time()\n",
    "    net.train()\n",
    "    logits = net(g, features)\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch >= 0:\n",
    "        dur.append(time.time() - t0)\n",
    "    acc = evaluate(net, g, features, labels, test_mask)\n",
    "    print(\n",
    "        \"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
    "            epoch, loss.item(), acc, np.mean(dur)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a474e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
